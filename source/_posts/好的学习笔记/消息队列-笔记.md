---
title: 笔记-消息队列
categories: 好的学习笔记
tags: 消息队列
---



# 消息队列 RedisMq

### 前提

* 某些场景下我们无法使用消息中间件提供消息队列功能，而需要使用Redis实现消息队列的功能时，可以引用该项目实现消息队列功能。
* 这是一个使用基于 Redis 列表数据类型实现的具有消息队列功能的项目，该项目建立在 Spring Boot 框架之上，通过 Spring 提供的RedisTemplate 功能访问 Redis 服务，并利用 Spring Boot 自动配置的功能可以方便的注入其他项目中使用。



### 使用流程

1. 配置
2. 定义生产者业务
3. 定义消费者业务



#### 1、配置

略............



#### 2、生产者

> redisTemplate.convertAndSend




![image-20230204113448688](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230204113448688.png)



#### 3、消费者

> MessageListener

![image-20230204101550596](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230204101550596.png)



> 自定义 AbstractChannelMessageListener

![image-20230204101640379](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230204101640379.png)





![image-20230204103039418](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230204103039418.png)



![image-20230204103035624](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230204103035624.png)



> 自定义实现 FileConfigRefreshConsumer

![image-20230204101734590](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230204101734590.png)





# 消息队列 RabbitMq

## 一、前提

> [Rabbit 和 Kafka 的选择](https://mp.weixin.qq.com/s/c_o5HIsQKVQmC6aiCtU8bg)
>
> [为啥不能多个消费者同时消费同一个队列](https://blog.csdn.net/weixin_39717865/article/details/111618689)



## 二、RabbitMq 架构图

![image-20230404163709676](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230404163709676.png)



【问题】RabbitMQ 中的消息是基于队列进行存储和传递的，那么消息被消费之后是不是就从队列移除了？

![image-20230530150353835](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230530150353835.png)



【问题】多个消费者可以同时连接到同一个队列，然后消费到相同消息吗？

* 当然不行，多个消费者可以同时连接到同一个队列，那么每个消费者只会收到队列中的一部分消息。收到哪个消息就是通过负载均衡机制会进行消息的轮询分发的。
* 如果想消费同一个消息，就让服务启动时自己生成多个通配符队列。



【问题】每一个订阅了交换器的消费者都会创建一个队列，这句话怎么理解？

* 交换机会将消息按照规则分配到消费者连接的队列上。



【问题】RabbitMq 多个消费者绑定同一个队列时，怎么确定消息是被哪个消费者消费的，消息被消费到哪个位置？比较 

* By the way，kafka 是有 offset 来保证的。

![image-20230530144109856](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230530144109856.png)





## 三、消息交换器

* 发布者可以把消息发布到消息交换器上而不用知道这些消息都有哪些订阅者。
* 每一个订阅了交换器的消费者都会创建一个队列；然后消息交换器会把生产的消息放入队列以供消费者消费
* 消息交换器也可以基于各种路由规则为一些订阅者过滤消息。



![image-20230404163634244](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230404163634244.png)





## 四、路由规则

支持四种路由规则：direct、fanout、topic、headers、

### 1、direct

direct，根据路由关键字完全匹配队列名。

如下图所示。

![image-20231221144542540](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20231221144542540.png)



### 2、fanout

fanout，发送到所有绑定的队列。



### 3、topic

topic，根据路由关键字进行通配符匹配。

* 星号，仅代表一个单词
* 井号，代表任意个单词



如下图所示。

![image-20231221144806574](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20231221144806574.png)





### 4、headers

headers，可看作 topic 的增强版。路由关键字是一组键值对，通过多组条件组合匹配。

![image-20231221145010978](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20231221145010978.png)



# 消息队列 RabbitMq 的死信队列和延迟队列的区别

### 前提

**延时队列**：

* 队列内部是有序的,最重要的特性就体现在它的延时属性上，延时队列就是用来存放需要在指定时间被处理的元素的队列, 延时队列其实就是特殊的死信队列

**死信队列**：

* 死信队列是指消息被投递到队列后，由于各种原因导致队列中的消息无法被消费掉，这样的消息如果没有后续处理就变成了死信，有死信自然就有了死信队列。
* 消息变成死信后，会被重新投递（publish）到另一个交换机上（Exchange），这个交换机往往被称为DLX(dead-letter-exchange)“死信交换机”，然后交换机根据绑定规则转发到对应的队列上，监听该队列就可以被重新消费。



### **死信的来源**

* 消息TTL过期
* 队列达到最大长度（队列满了，无法再添加到队列中）
* 消息被拒绝（basic.reject或basic.nack）



### 死信队列的应用场景

1. 为保证订单业务消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息消费发生异常时，将消息投入死信队列中。该消息会被重新消费。
2. 实时捞取库中超时的订单：当客人提交订单后，在规定的支付时限内，迟迟没有付款。在电商交易环节，提交订单，预示着预锁了库存，超时未支付，需要及时取消订单，释放库存。



### 基于死信队列存在的问题

* 正常消息可能并不会按时"死亡"。因为数据结构是队列，它需要等待第一个消息过期后才会执行第二个消息。
* 因为它只会检查第一个消息是否过期，如果过期则丢到死信队列，如果第一个消息的延时时长很长, 而第二个消息的延时时长很短，第二个消息也不会优先得到执行，而是在第一个消息过期后才会执行。



### 死信队列中存在问题的解决方案

基于 ”插件“ 的延迟队列方式，可以很好的解决死信队列中每次只会监测第一个消息的过期时间，基于插件的延迟队列不会受先后顺序影响，而只受其延迟时间影响, 延迟时间短的 , 便会先发送出去。



### 总结

死信队列保障消息至少被消费一次以及未被正常处理的消息不会被丢弃。总的来说，死信队列只是在作为延时队列的时候存在一些小问题，但在其他方面的使用是非常完美的。

延时队列还有很多其他选择, 如利用 java 的 DelayQueue, 利用 Redisdzset ,利用 quartz 或者利用 kafka 的时间轮, 都各有特点。





# 消息队列 RabbitMq 的使用

### 前提

### 使用流程

1. 配置
2. 定义生产者业务
3. 定义消费者业务



#### 1、配置

> Binding：外部消息传递系统和应用程序之间的桥梁



![image-20230210110758593](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230210110758593.png)



#### 2、生产者

> rabbitTemplate.convertAndSend



![image-20230210110321526](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230210110321526.png)



#### 3、消费者

> @RabbitListener



![image-20230210110254075](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230210110254075.png)







# 消息队列 Kafka

### 前提

> [Kafka介绍](https://blog.csdn.net/weixin_39785524/article/details/112737400)
>
> [后kafka时代下的消息队列，Kafka还会走多远？](https://zhuanlan.zhihu.com/p/406856732)



**设计理念：**

设计理念非常简单，就是一个以【append-only 日志作为核心的数据存储结构】。

HDD 的随机读取和写入因为其本身原因会非常慢，但其实如果能够把所有的读和写都按照顺序来进行操作，会发现它几乎可以媲美内存的随机访问。kafka 利用 append-only 日志作为核心的数据存储结构，只会对文件进行顺序的读写操作，大大的利用了这一优点。

> 机械硬盘的连续读写性能很好，但随机读写性能很差，这主要是因为磁头移动到正确的磁道上需要时间，随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上，所以性能不高。衡量磁盘的重要主要指标是 IOPS 和吞吐量。



**Topic 和 Partition：**

Topic 只是一个逻辑的概念。每个 Topic 都包含一个或多个 Partition(队列)，不同 Partition 还可以分配在不同节点上。

> 一方面。由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。
>
> 另一方面。由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。



**offset：**

* 每个消费组都会有自己的一个消费点 (offset) 来表示消费到的位置，在消费点之前的消息说明这个消息已经被同一个消费组和其他消费者消费过了，如果这个 offset 是队列级别的，每个消费者都会维护订阅的 Topic 下的每个队列的 offset。
* By the way，RabbitLMq 是通过【消息确认机制】来实现类似的功能。

![image-20230303153755909](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230303153755909.png)



**幂等：**

幂等就是使用同样的参数多次调用同一个接口和一次调用同一个接口执行结果是一样的。



**Redis BloomFilter：**

Redis BloomFilter 是一个基于 Redis 的布隆过滤器实现，可以用来处理消息队列中的重复消息。



### Kafka架构图

![image-20230303180711311](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230303180711311.png)



### 异步处理和服务解耦

* 随着业务的不断扩展，需要用消息队列实现异步处理，从而减少处理请求的等待时间，让服务异步并发处理，提升系统的总体性能。
* 订单服务下游还有短信服务和积分服务，如果现在还要加营销服务和数据分析服务，甚至更多的服务，为了迎合下游服务的改动，订单服务需要经常修改，这订单服务项目组也太难受了吧！



![image-20230303153038354](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230303153038354.png)



### 流量控制

在并发量级很大的情况下，比如秒杀活动爆发式的流量打入后台，后台很可能会顶不住，所以就需要一个中间件，先将请求全部放入消息队列。



# Kafka 如何保证消息不丢失？

### 前提

一共有生产消息、存储消息、消费？消息三个阶段，下面就以这三个阶段入手看看如何保证消息不丢失。



### 1、生产消息

生产者发送消息至Borker，需要对 Broker 的响应进行处理，不管是同步发送消息还是异步发送消息，都需要做好 try-catch 对 Broker 的响应做出妥善的处理，如果 Broker 返回写入消息失败等其他错误信息，生产者需要重新发送消息至 Broker，如果多次发送失败则需要报警并且记录日志。这样可以保证消息在生产阶段不会丢失。



### 2、存储消息

存储消息阶段需要等待消息写入磁盘(消息刷盘)之后再给生产者做出响应。因为如果消息仅仅写入了内存就给生产者响应的话，这个时候如果断电导致机器停了，那么消息也就没了，但是生产者却以为消息已经存储成功了。

如果 Borker 是集群部署，有多副本机制，那么消息不仅仅要写入当前 Broker，还需要写入副本机器中，那么必须等待消息写入两台机器之后再给生产者做出相应，这样就可以保证消息在存储阶段不丢失了。



### 3、消费消息

消费者拿到消息之后，等他真正执行完逻辑之后，也就是处理完消息之后，再给 Borker 做出相应，如果在消费者刚拿到消息就做相应的话，消费者宕机了，那这消息就没了！这样就可以保证消息在消费阶段不会丢失了。



### 总结

嗯嗯？好像 Kafka 更多是需要在业务上保证的，但是 RabbitMq 则是可以通过自带的【消息确认机制】保证。



# Kafka 如何处理重复消息？

【问题】消息重复是怎么出现的？

生产阶段：

在生产消息阶段生产者需要等待 Broker 的响应，这时候如果网络出现问题，导致生产者没有收到相应，那么生产者会再次重复发送，这样Broker中就会有两条重复的消息了！



消费消息阶段：

如果一个消费者已经完成了消息的所有业务处理，在最后准备更新 Consumer offset 了，消费者挂了！所以此时另一个消费者还是会拿到刚才那条消息再重复执行一次，这就造成了消息重复消费！



### 如何处理重复消息

从正常的业务流程来看，消息重复好像是不可避免的，因为我们总不能为了解决消息重复的问题又导致消息丢失的问题吧！那么我们换个角度去思考这个问题。

既然我们不能避免消息的重复，那么我们就对因为消息重复带来的业务上面的影响进行处理，关键点就在于幂等。



方案1：消费者加锁

> https://www.cnblogs.com/shanml/p/16909874.html



【问题】为什么集群模式下需要加锁？

* 因为在广播模式下不存在竞争关系，一个消息队列同一时刻只能被同一个消费组下的某一个消费者进行也就不需要对消息队列进行加锁
* 而在集群模式下，有可能因为负载均衡等原因将某一个消息队列分配到了另外一个消费者中（多个副本的情况下）。



![image-20230306151115632](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230306151115632.png)



![image-20230306151218650](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230306151218650.png)





方案2：存储唯一键

* 使用数据库唯一约束，如Redis、Mysql
* Redis 布隆过滤器
* 等等.....................



![image-20230306151836047](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230306151836047.png)



![image-20230306151906382](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230306151906382.png)



### 总结

嗯嗯？好像和【如何保证消息不丢失】类似， Kafka 更多是需要在业务上保证的，但是 RabbitMq 则是可以通过自带的【消息确认机制】保证。





# Kafka 如何保证消息的有序性？

### 1、全局有序

必须只有一个生产者往 Topic 中发送消息，并且 Topic 中只有一个队列(分区)，消费者必须单线程消费这个队列(分区)中的消息，这样消息就是全局有序的，但是一般我们不需要全局有序。



### 2、部分有序

* 变相一对一而已

* 通过特定的策略将消息发送给指定的队列，然后每个队列对应一个单线程的消费者去消费队列中的信息，这样既可以实现消息的部分有序，还可以通过Topic中队列的数量提高并发处理消息的效率。

![image-20230303155440594](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230303155440594.png)



### 总结

结合【Kafka 和 RabbitMq 的获取消息的方式】，Kafka是消费者主动获取消息，消费者本身会记录消息的 offset，之后就不会再进行重复消费了。

相比之下，RabbitMq 更多是保证消息的可用性，因为在 RabbitMq 中消息处理异常的话它服务器会将消息再次分配给其它消费者。





# Kafka 的 partition

### 前提

【问题】为什么 kafka 有分区的概念？

* Kafka 有严格的消息顺序是因为它是一个分布式系统，一个主题（Topic）的消息可能被分布在不同的分区（Partition）中，而每个分区又可能被分布在不同的服务器上。为了保证消息的顺序性，Kafka 引入了分区的概念，每个分区内的消息是有序的，而不同分区的消息则是并行处理的。

* 在 Kafka 中，每个分区都有一个唯一的标识符（Partition ID），并且每个分区内的消息都有一个对应的偏移量（Offset），用于标识消息在分区内的位置。因此，Kafka 可以保证同一分区内的消息是按照顺序被消费的。

* 此外，Kafka 还提供了消费者组（Consumer Group）的概念，多个消费者可以组成一个消费者组来消费同一个主题的消息。Kafka 保证同一消费者组内的消费者不会同时消费同一个分区内的消息，因此可以保证同一分区内的消息被顺序消费。

  

  总之，Kafka 严格保证消息的顺序性，这是因为在分布式系统中，保证消息顺序性是非常重要的，特别是在一些对消息顺序性要求较高的场景下，例如金融交易、游戏逻辑等。

 

【问题】消息顺序影响了什么？

* 消息顺序影响的是业务，因为有些业务是必须有序的。消息队列结构了业务操作，但是业务操作业务需要有序的。
* 比如三个指令按循序更新数据库，最终结果应该是3，如果消息顺序没有保证，最终可能是1或2。



### Topic 和 Partition

Topic 只是一个逻辑的概念。每个 Topic 都包含一个或多个 Partition(队列)，不同 Partition 可位于不同节点。

* 一方面。由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。
* 另一方面。由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。

由于 partition 之间的数据是没有办法保证有序，且没有业务逻辑关系的。默认情况下，当用客户端向某个 topic 灌数据时，如果没有指定消息的 key 和要写入的 partition，那么数据会以 round-robin 的方式均匀写到 topic 的每个 partition 中。



### 根据业务特点确定partition数量

1、假如这些数据来自全国各地，而你后续要对这个数据根据各个省份的登录情况进行汇总统计。如果根据省份分组这个业务特点，将你的 partition 数量设置为省份的个数，且每条数据在写入 partition 前以当前省份作为消息的key。

![image-20230303175028587](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230303175028587.png)



2、iot 系统中，业务是针对每一款设备。所以可以根据设备编号作为 partitionKey。

![image-20230303175313773](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230303175313773.png)



可以参考，[IoT 设备消息洪峰怎么扛](https://xie.infoq.cn/article/45f643dcf0fcad40924ca87b5) 的实现。

![image-20230829102843293](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230829102843293.png)





### Partition 数量过多有什么问题

> [Kafka的partition数量过多有什么问题](https://blog.csdn.net/weixin_38107388/article/details/107827764?spm=1001.2101.3001.6650.9&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-107827764-blog-114626337.pc_relevant_recovery_v2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-9-107827764-blog-114626337.pc_relevant_recovery_v2&utm_relevant_index=10)



#### 1、太多的partition需要打开更多文件句柄

每个partition在broker的文件系统上都映射着对于的文件夹。 在文件夹里面，每个segment（partition下的存储单位）会有两个文件，一个是索引，另一个是消息数据。每个broker都会为每个segment打开两个文件句柄。所以如果parition太多的话，你就需要在操作系统里配置下可以同时打开的文件句柄数以使得可以支撑如此之多的segment。曾经见过一个kafka集群，里面的broker平均同时打开了30000多个句柄（约15000个分区）。



#### 2、太多的partition导致可用性降低

一个partition对应着多个副本。在一个broker优雅退出时，集群的controller会提前地将该broker上的leader迁移到其他broker上。 迁移一个leader只需要几毫秒的时间，所以从客户端角度来说，这只会有一小段时间不可用（只在迁移时的时间不可用，毫秒级）

然而如果一台broker是被粗暴的退出了，那不可用时间就取决于partition的数量了。



#### 3、太多的partition增加了消息的延迟

> 消息的延迟指的是一条消息从生产者发送到被消费者消费的时间差。 Kafka只会把已经被所有副本复制成功的消息下发给消费者。partition是可以分布在不同Broker节点下的，而且kafka的broker只使用单线程去从其他broker里复制消息。





# 消息队列 如何处理重复消费

### 前提

> 除了Bloom过滤器，还有其他技术可以解决重复消息消费的问题呢？



![image-20230425143447459](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230425143447459.png)



### 1、使用持久存储重复数据

将处理后的消息id存储在数据库或分布式缓存(如Redis、Memcached)中。在使用消息时，检查其ID是否已经在数据存储中。如果是，则跳过对消息的处理；否则，处理它并将其ID添加到数据存储或分布式缓存中。



![image-20230425170218171](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230425170218171.png)



### 2、幂等消息处理

将消息处理逻辑设计为幂等的，这意味着多次处理相同的消息与处理一次消息具有相同的效果。这种方法依赖于业务逻辑来处理重复，而不需要像Bloom过滤器或数据库这样的重复数据删除机制。



![image-20230425143113154](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230425143113154.png)



### 3、Kafka：精确一次的消息传递

一些消息传递系统，如Apache Kafka，可以提供精确一次的消息传递语义，它保证每条消息将被精确地传递和处理一次。这可以通过生产者、经纪人和消费者之间的交易和强有力的一致性保证来实现。



![image-20230425172341199](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230425172341199.png)



### 4、RabbitMq：消息确认

在像RabbitMQ这样的消息传递系统中，你可以使用【消息确认】来确保消息只有在被消费者确认后才被认为是“已处理”的



![image-20230425172503445](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230425172503445.png)



### 在Redis中使用持久存储和在Redis中使用Bloomfilter是一样的吗？

> 虽然在Redis中使用持久存储和使用Redis的布隆过滤器都可以帮助防止重复的消息消费，但它们并不相同。
>
> 这两种方法都可以帮助您防止重复消息的消耗，但是它们在存储消耗、重复检测准确性和速度方面有不同的权衡。

使用Redis作为持久存储：当你直接在Redis中存储消息ID时，你可以检查一个消息ID是否存在于数据存储中。这种方法提供了精确的重复检测，但是存储消耗将随着消息id的数量线性增长。Redis还提供数据持久化选项，将数据保存在磁盘上，确保系统崩溃时的持久性。

使用Redis布隆过滤器：当你在Redis中使用Bloom过滤器时，你可以利用Bloom过滤器的概率性质和内存效率来存储消息id。这种方法允许小概率的假阳性，但保证没有假阴性。它提供了一种高效且节省空间的方法来跟踪处理过的消息id，但可能不如直接在Redis中存储消息id准确。

总之，这两种方法都可以帮助您防止重复消息的消耗，但是它们在存储消耗、重复检测准确性和速度方面有不同的权衡。





# 消息队列 Kafka 的痛点

### 前提

> [后kafka时代下的消息队列，Kafka还会走多远？](https://zhuanlan.zhihu.com/p/406856732)



### 单机器的分区上限问题

虽然 Kafka 的 topic partition 是顺序写入，但是当 broker上有成百上千个topic partition 时，从磁盘角度看就变成了随机写入，此时磁盘读写性能会随着 topic partition 数量的增加而降低。

> 因此 Kafka broker 上存储的 topic partition 数量是有限制的。



### Kafka不支持读写分离

> 在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。 Kafka 并不支持主写从读。

其实kafka的主写主读也是有一些优点的：

1. 可以简化代码的实现逻辑，减少出错的可能;
2. 将负载粒度细化均摊，与主写从读相比，不仅负载效能更好，而且对用户可控;
3. 没有延时的影响;
4. 在副本稳定的情况下，不会出现数据不一致的情况。



### PageCache 污染问题，造成读写性能下降

Kafka对page cache需求巨大。根据经验值，为Kafka分配6~8GB的堆内存就已经足足够用了，将剩下的系统内存都作为page cache空间，可以最大化I/O效率。

另一个需要特别注意的问题是 Lagging consumer，即那些消费速率慢、明显落后的consumer。它们要读取的数据有较大概率不在broker page cache中，因此会增加很多不必要的读盘操作。比这更坏的是，它读取的“冷”数据仍然会进入page cache，污染了多数正常consumer要读取的“热”数据，连带着正常consumer的性能变差。在生产环境中，这个问题尤为重要。



### 非存储与计算分离的架构

kafka并不是一个存储与计算分离的架构，因此无法从存储和计算单个维度进行扩容。

数据存储和消息队列服务绑定，集群扩缩容/分区均衡需要大量拷贝数据，造成集群性能下降，并且带来了很大的运维成本。





# RabbitMQ 和 Kafka 如何选择？

### 前提

【问题】Kafka 和 RabbitMq 的获取消息的方式是什么？

![image-20230530151050819](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230530151050819.png)



### 如何选择

优先选择 RabbitMQ 的条件：

- 高级灵活的路由规则；
- 消息时序控制（控制消息过期或者消息延迟）；
- 高级的容错处理能力，在消费者更有可能处理消息不成功的情景中（瞬时或者持久）；
- 更简单的消费者实现。

优先选择 Kafka 的条件：

- 严格的消息顺序；【为什么kafka有分区的概念？】【消息顺序影响了什么？】
- 延长消息留存时间，包括过去消息重放的可能；
- 传统解决方案无法满足的高伸缩能力。



### 总结

当开发复杂的软件系统时，我们可能被诱导使用同一个消息平台去实现所有必须的消息用例。但是，从我的经验看，通常同时使用这两个消息平台能够带来更多的好处。

例如，在一个事件驱动的架构系统中，我们可以使用 RabbitMQ 在服务之间发送命令，并且使用 Kafka 实现业务事件通知，因为命令它不关心消息顺序，关心消息时序。业务更关心消息顺序。





# 消息队列与 Spring Cloud Stream

## 一、前提



【问题】stream 是什么，为什么要使用 stream？

SpringCloud Stream 是一个构建消息驱动微服务的框架，为了适配底层消息队列的一个抽象出来的中间件。降低切换版本，统一消息的编程模型。



## 二、配置

配置分为了通用配置和专属配置。

如下图所示。

![image-20231221151326424](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20231221151326424.png)



### 1、通用配置

* bindings：定义了消息通道的配置。每个通道都有一个名字，如 cospowerBoxCommandOutput，并且可以配置为生产者或消费者。
* binder：指定该通道使用的消息中间件类型。如果没有指定，则使用 default-binder 的值。
* destination：指定该通道对应的【消息队列名（rabbit）或主题名（kafka）】。
* group：消费组



### 2、rabbitMq 专属配置

* consumer.bindingRoutingKey：路由键，用于确定消息应该发送到哪个队列。
* consumer.prefetch：预取数量，用于指定 RabbitMQ 在没有收到消费者的确认前可以发送的消息数量。
* producer.routing-key-expression：路由键表达式，生产者发送的消息应该被路由到哪个队列。



【问题】consumer.bindingRoutingKey 和 producer.routing-key-expression 怎么理解？

不就是，保证生产的消息“主题”要和消费者想要的一致嘛。



## 二、@Input 与 @Output

Spring Cloud Stream 应用可以有任意数目的 input 和 output 通道，后者通过 @Input 和 @Output 注解在接口中定义。

如下图所示。

![image-20230130141050967](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230130141050967.png)



![image-20230130141121625](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230130141121625.png)



## 三、消费者：@StreamListener（receiver）

定义在方法中，被修饰的方法注册为消息中间件上数据流的事件监听器，注解中属性值对应了监听的消息通道名。

如下图所示。

![image-20230130141219128](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230130141219128.png)



## 四、生产者：@EnableBinding 触发绑定（sender）

将 @EnableBinding 注解添加到应用的配置类，就可以把一个 spring 应用转换成 Spring Cloud Stream 应用，@EnableBinding 注解本身就包含 @Configuration注解，会触发 Spring Cloud Stream 基本配置。

如下图所示。

![image-20230130142053743](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230130142053743.png)





# 消息队列与 Spring Cloud Stream-函数式编程

## 一、前提

在Stream v2.1版本之后支持函数式编程，[Spring Cloud Stream-函数式编程](https://docs.spring.io/spring-cloud-stream/docs/current/reference/html/spring-cloud-stream.html#spring_cloud_function) 。注解全部弃用了，@Input @Output @EnableBinding @StreamListener。



## 二、配置

### 1、专属配置

对比之前，会发现有以下这两个地方的配置不同了。

* function：定义消息处理的函数，对应的是生产者/消费者的 bean 名称。
* 消息通道名称：【csmsMoorIvr-in-0】表示将这个通道绑定到 bean 名称为 csmsMoorIvr上，并且通道类型是输入。



* consumer.bindingRoutingKey：路由键
* exchangeType：交换机类型，不填默认是 topic。
* acknowledge-mod：自动签收还是手动签收
* producer.routing-key-expression：【headers.routeId】消息表示根据请求头中的 routeId 进行路由。（在发送消息时显示添加了请求头 routeId==key）



### 2、通用配置

* binder：rabbit
* destination：对应交换机
* group：对应队列



![image-20231222113854362](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20231222113854362.png)



## 三、消费者

【@StreamListener，@Input】注解弃用。改为在配置文件中消息通道声明时直接指定是输入类型。如【csmsMoorIvr-in-0】。

如下图所示。

![image-20231222114039670](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20231222114039670.png)

## 四、生产者

【@EnableBinding】被弃用，它是通过【StreamBridge】来发送消息的。【@Output】被弃用，改为在配置文件中消息通道声明时直接指定是输入类型。如【csmsMoorIvr-out-0】。

如下图所示。

![image-20231222114436350](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20231222114436350.png)







## 五、对比文件结构

之前，如下图所示。

![image-20231221161049602](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20231221161049602.png)



现在，如下图所示。

![image-20231221161141968](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20231221161141968.png)







# UniIOT Kafka 的使用

### 前提

uniiot 响应的业务处理将消息封装，消息里存放了关键信息“serviceName”，并将推送到指定的topic。消费者初始化后，不断地监听对应topic的消息，然后解析消息得到“serviceName”。然后调用该service的tellMsg()，对收到该消息后进行相应的业务处理。



### 使用流程

1. 配置
2. 定义生产者业务
3. 定义消费者业务



#### 1、关键的 QueueMsg 和 serviceName

![image-20230328150411866](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230328150411866.png)



![image-20230328150541926](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230328150541926.png)



#### 2、生产消息

![image-20230328151554882](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230328151554882.png)



#### 3、消费消息

> uniot 处理消息是异步返回的，因为有根据错误触发自定义重试机制



![image-20230328152418539](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230328152418539.png)



![image-20230328150818593](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230328150818593.png)





注意看父类 OnLineService 和 OffLineService 等继承了AbrApplicationService，它们没有实现通用 tellMsg() 方法，所以会调用父类 AbrApplicationService 的tellMsg() 方法，比其它的业务处理多了一层特别的处理。

AbrApplicationService 的业务处理是：1、进行子类 service 的业务处理。2、再将消息转发到【Disruptor 实现的规则引擎】，将消息发布到 Disruptor 的订阅者。如数据持久化等。



### 总结

#### 1、通用抽象

如果某一个继承而来的通用方法需要额外的通用逻辑，那就再继承该类，实现通用的逻辑。如 iot 的实现，消息监听会统一调用 “tellMsg()”，但是 onLineService、offLineService 的服务还需要“缓存消息和通知其它设备”。于是再将 onLineService、offLineService 抽象出父类实现 tellMsg()。tellMsg 时就会调用到 onLineService 的父类方法。接着“缓存消息和通知其它设备”的实现还可以在父类统一实现。



![image-20230330105256528](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230330105256528.png)





#### 2、不用业务处理

不同的消息进行不同的业务处理，除了在消息队列层面分配不同的 topic 以外。也可以在业务上进行处理，也就是在消息中加入标识。当收到消息后，再通过标识找到对应的业务处理服务。

SpringBoot 提供了很多获取服务的方式：

* 可以直接通过 ApplicationContext 的 getBean() 方法。
* 可以通过 InitializingBean 类中的 afterPropertiesSet，启动的时候报错服务到 map中，后续再从 map 中获取。





# Disruptor-Mq

## 一、前提

Disruptor 它可以用来作为高性能的有界内存队列， 适用于两大场景：

- 生产者消费者场景，Disruptor 的最常用的场景就是“生产者-消费者”场景，对场景的就是“一个生产者、多个消费者”的场景，并且要求顺序处理。
- 发布订阅场景，Disruptor也可以认为是观察者模式的一种实现， 实现发布订阅模式。

当前业界开源组件使用 Disruptor 的包括 Log4j2、Apache Storm 等。



## 二、配置

组合起来完成一个完整的事件处理系统

### 1、Test1

![image-20230224144405306](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230224144405306.png)



### 2、Test2

![image-20230224144444128](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230224144444128.png)



### 3、Test3

![image-20230224142211664](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230224142211664.png)







## 三、消费者：

消费者有多个，在初始化 Disruptor 的时候需要将消费者绑定到 disruptor 上。

消费着可以单独声明，可以使用事件 ’onEvent ‘触发（gyyx）。也可以不单独声明，使用默认的 onEvent 实现（unilumin）。

**gyyx 用 disruptor来处理：**

* 客户端注册
* 心跳检查
* 客户端响应信息
* 客户端关闭连接
* 下发命令

**unilumin 用 disruptor 来处理：**

* 客户端响应数据持久化到数据库
* 客户端告警数据处理
* 规则引擎处理
* 订阅消息处理



![image-20230224142109324](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230224142109324.png)





## 四、生产者：

### 1、Test1

需要发布消息是就调用封装了ringBuffer.publish 方法的 publish() 方法。

![image-20230224141904130](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230224141904130.png)



![image-20230224144210351](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230224144210351.png)





### 2、Test2

需要发布消息是就调用封装了 ringBuffer.publish 方法的 tellMsg() 方法。

![image-20230224141619354](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230224141619354.png)

![image-20230224141722183](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230224141722183.png)



## 五、总结

与 Kafka、RabbitMQ 用于服务间的消息队列不同，disruptor 一般用于线程间消息的传递。基于 Disruptor 开发的系统单线程能支撑每秒 600 万订单。disruptor 只是数据交换快，适合不同线程间需要快速交换数据， 在大数据开发中和一些中间件开发中会有用武之地。 



uniiot 主要用它来对【 属性、遥测、服务、事件】消息进行过滤，因为这些是大数据量。对比如下：

* 如果使用单线程，服务器资源就那么多，如果 ruleEngineService 服务链路上，那么 MQ 消息就会发生积压。
* 如果使用多线程，消息的数量非常多时，线程池数量不够用，会发生锁等待。
* 使用 Distruptor ，无锁设计，线程级别的“异步”处理。



# EventBus-Mq

### 前提

**事件总线**：

* com.google.common.eventbus 是 Google Guava 库中的一个模块，提供了一个简单的发布/订阅事件模型，用于在应用程序中实现松散耦合的组件之间的通信。
* 它基于观察者模式，通过使用注解和反射机制，可以轻松地将事件处理程序注册到事件总线中，并在事件发生时自动调用这些处理程序。
* 它还提供了异步事件处理、事件过滤和优先级等功能，可以满足不同场景下的事件处理需求。使用 com.google.common.eventbus可以有效地简化应用程序的设计和实现，提高代码的可读性和可维护性。



### Disruptor 和 eventbus 的区别

> Disruptor 和 EventBus 都是用于实现事件驱动架构的工具。

EventBus 是一个轻量级的事件总线框架，它可以帮助开发人员实现松耦合的事件驱动架构。EventBus 使用了观察者模式，可以让开发人员在应用程序中定义事件和监听器，并将它们注册到总线上。当事件发生时，总线会通知所有监听器进行处理。

Disruptor 是一种高性能的内存消息传递框架，它可以在不使用锁的情况下实现高并发的消息处理。Disruptor 使用了一种叫做环形缓冲区的数据结构，可以实现非常高效的事件发布和订阅。



### 使用流程

1. 配置
2. 定义生产者业务
3. 定义消费者业务



#### 1、配置

![image-20230327171214370](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230327171214370.png)



#### 2、生产者

![image-20230327171529000](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230327171529000.png)



#### 3、消费者

![image-20230327171346491](https://note-1305755407.cos.ap-nanjing.myqcloud.com/note/image-20230327171346491.png)





### 总结

EventBus 适合处理较少的、低频率的事件，例如用户界面事件等。Disruptor 适合处理大量的、高频率的事件，例如金融交易系统等。

总的来说，Disruptor 和 EventBus 都是非常有用的工具，可以帮助开发人员实现高效、可扩展、可维护的事件驱动架构。选择哪个工具取决于具体的应用场景和需求。

